{"ast":null,"code":"export default {};","map":{"version":3,"names":[],"sources":["/Users/tanghaoyun/Documents/GitHub/WebSiteForLab/web-zhang/src/components/Research/ResearchInterests.vue"],"sourcesContent":["<template>\n    <div class=\"research-content\">\n        <ul>\n            <li class=\"research_sentence\">\n                &nbsp;&nbsp;&nbsp;&nbsp;The Zhang has a long history of research on heuristic search, planning and optimization. The work has made significant contributions to the understanding of the nature and complexity of many search techniques, such as best-first search and depth-first branch-and-bound, and combinatorial optimization problems, such as the Traveling Salesman Problem and Constraint Satisfaction.\n            </li>\n            <li class=\"research_title\">Asymptotic optimality of linear-space search algorithms: </li>\n            <li class=\"research_sentence\">\n                &nbsp;&nbsp;&nbsp;&nbsp;THeuristic search is one of the cornerstone of AI. The best-first search (BFS) algorithm, with the well-known A* algorithm as a special case, is time optimal. However, it requires space that is exponential in the search depth of the underlying search tree, which is impractical for large combinatorial optimization problems, such as the Traveling Salesman Problem (TSP).\n                In contrast, a linear-space search (LSS) algorithm, with depth-first search and depth-first branch-and-bound (DFBnB) as special cases, runs linearly in search depth with a penalty of exploring more nodes in the search space. Due to their limited space requirement, LSS algorithms, including DFBnB, iterative deepening A* (IDA*), and recursive best-first search (RBFS), are the most popular techniques \n                for large and difficult search problems in practice. Understanding the expected complexity of LSS algorithms was an important and challenging problem.Based on a random search tree model proposed by Judea Pearl and Richard Karp,<b>our research established the <u>asymptotic optimality</u> of LSS methods</b>, showing that their expected complexity is a constant factor of that of BFS (<a class=\"research_link\" href=\"https://www.cse.wustl.edu/~weixiongzhang/\" target=\"_blank\">Zhand and Korf, Artificial Intelligence, \n                79(2):241-92, 1995</a>; <a class=\"research_link\" href=\"https://link.springer.com/book/10.1007/978-1-4612-1538-7\" target=\"_blank\">Zhang, State-Space Search, Springer, 1999</a>). Moreover, LSS algorithms may run faster than BFS on large problems, making them the algorithms for real applications.\n                <br/>\n                &nbsp;&nbsp;&nbsp;&nbsp;A directly and early application of our complexity results is the explanation to anomaly of the fixed horizon search, which was observed initially by Richard Korf on sliding-tile puzzles using DFBnB, as illustrated below. The anomaly states that for a fixed search depth, DFBnB can search the trees with larger branching factors faster. In fact, the anomaly persists regardless which search method, e.g., ID (or IDA*) or RBFS, shown below.\n                <li>\n                <img class=\"research_img_1\" src=\"\thttps://genomicmedicine.github.io/site/picture/0/dd7eea7dbc684d22aa404423aca5e170.png\">\n                <img class=\"research_img_2\" src=\"https://genomicmedicine.github.io/site/picture/0/24b0a4109cf841159f9678ca1c488c97.png\">\n                </li>\n            </li>\n            <li class=\"research_sentence\">\n                &nbsp;&nbsp;&nbsp;&nbsp;The insight gained by the complexity analysis on this search anomaly helped predict the existence of a phase transition in heuristic search problems, discussed below.\n            </li>\n\n\n            <li class=\"research_title\">Phase transitions and structures of combinatorial search: </li>\n            <li class=\"research_sentence\">\n                &nbsp;&nbsp;&nbsp;&nbsp;Our study also revealed that the expected complexity of BFS and LLS algorithms exhibits a sharp and abrupt transition from polynomial to exponential time as some critical problem features \n                (e.g., the precision of heuristic function) shift (<a class=\"research_link\" href=\"https://www.cse.wustl.edu/~weixiongzhang/\" target=\"_blank\">Zhand and Korf, Artificial Intelligence, 79(2):241-92, 1995</a>;<a class=\"research_link\" href=\"https://www.cse.wustl.edu/~weixiongzhang/\" target=\"_blank\">Zhang and Korf, Artificial Intelligence, 81(1-2):223-39, 1996</a> ; \n                <a class=\"research_link\" href=\"https://link.springer.com/book/10.1007/978-1-4612-1538-7\" target=\"_blank\">Zhang, State-Space Search, Springer, 1999</a>). This is similar to phase transitions of spin glasses studied in physics. A simple example of a phase transition is water changing from liquid to solid ice \n                when the temperature drops below the freezing point. We identified that the accuracy of heuristic information is the controlling parameter of phase transitions. On the Judea&Karp incremental random \n                search tree model, the phase transition can be summarized by the following figure.\n                <li>\n                <img class=\"research_img_1\" src=\"\thttps://genomicmedicine.github.io/site/picture/0/2eac6d39e18b4de4b02f846110bb9b8e.png\">\n                </li>\n\n            </li>\n\n        </ul>    \n    </div>\n </template>\n\n <script>\n    export default {\n\n    }\n</script>\n\n<style lang=\"less\" scoped>\n\n.research_img_1{\n   margin-left: 10%;\n   width: 230px;\n   padding-bottom: 20px;\n}\n\n.research_img_2{\n   width: 460px;\n   padding-bottom: 20px;\n}\n\n</style>"],"mappings":"AA0CI,eAAe,CAEf"},"metadata":{},"sourceType":"module","externalDependencies":[]}